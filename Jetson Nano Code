#Code in Jetson Nano for detection

import jetson.inference
import jetson.utils
from jetson_inference import detectNet
from jetson_utils import videoSource, videoOutput
import numpy as np
import cv2
import smbus
import time
import serial

ser = serial.Serial('/dev/ttyTHS1', 9600)
x=660
coefficient=255/1024
distance=0

def send_number(number):
    # Direct sending of numbers (Taking into account ranges and coefficients)
    if 10 <= number <= 1024:
        # If the number is in the range 10 to 1024, multiply by the factor x and ensure that the result does not exceed 255
        number = round(number * coefficient)
    elif 0 <= number <= 9:
        # If the number is in the range of 0 to 9, send the direct
        pass
    else:
        print("Number out of allowed range. Not sending.")
        return
    
    if 0 <= number <= 255:
        ser.write(number.to_bytes(1, 'little'))
        print(f"Sent number: {number}")
    else:
        print(f"Error: Number {number} is out of the allowable range for 1 byte.")

# Specify model path and label file path
model_path = '/home/ljy/jetson-inference/python/training/detection/ssd/models/road_other_2/ssd-mobilenet.onnx'
labels_path = '/home/ljy/jetson-inference/python/training/detection/ssd/models/road_other_2/labels.txt'
input_blob = 'input_0'  # Adjust to the specifics of your model
output_cvg = 'scores'   # Adjust to the specifics of your model
output_bbox = 'boxes'   # Adjust to the specifics of your model

# Loading Models
net = detectNet(argv=["--model=" + model_path, "--labels=" + labels_path, "--input-blob=input_0", "--output-cvg=scores", "--output-bbox=boxes"], threshold=0.9)

# Creating video source and output objects
input = videoSource("csi://0")
output = videoOutput("display://0")

# Processing video frames
while True:
    # Capture next frame
    img = input.Capture()
    #img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
    # Detecting objects in an image
    detections = net.Detect(img)
    flag = False
    for detection in detections:
        class_id = detection.ClassID
        label = net.GetClassDesc(class_id)
        if label == "human":
            flag = True
            # Human detected. Send number 1.
            x2=1
            x_human = detection.Left + detection.Width / 2
            y_human = detection.Top + detection.Height / 2
            distance=1024*4.9/(detection.Height)
            distance_text = f"Distance: {distance:.2f} cm"
            img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            cv2.putText(img_np, distance_text, (int(x_human), int(y_human - 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
            if distance<=30:
                send_number(x2)
                print("RPI: Hi Pi, I detect a human ", x2)
            
        elif label == "stop":
            flag = True
            # Stop detected, send number 2
            x2=2
            x_stop = detection.Left + detection.Width / 2
            y_stop = detection.Top + detection.Height / 2
            distance=1024*4.9/(detection.Height)
            distance_text = f"Distance: {distance:.2f} cm"
            img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            cv2.putText(img_np, distance_text, (int(x_stop), int(y_stop - 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
            if distance<=30:
                send_number(x2)
                print("RPI: Hi Pi, I detect a stop ", x2)

    if not flag:   
        # If the best detected object exists, plot its midpoints
        road_detections = [d for d in detections if net.GetClassDesc(d.ClassID) == "road"]
        if road_detections:
            best_road_detection = max(road_detections, key=lambda d: d.Confidence)
            x = best_road_detection.Left + best_road_detection.Width / 2
            y = best_road_detection.Top + best_road_detection.Height / 2
            send_number(x)
            print("RPI: Hi Arduino, I sent you road center at", x)

            # Convert img to numpy array for drawing
            img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            cv2.circle(img_np, (int(x), int(y)), 5, (0, 0, 255), -1)  # 绘制中点

        else:
            # If no human, road or stop is detected, send 0
            x2 = 0
            img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            send_number(x2)
            print("RPI: Hi Pi, I sent you nothing", x2)

    # Display of test results
    img = jetson.utils.cudaFromNumpy(img_np)
    output.Render(img) 
    time.sleep(0.2)
    # Updating the status bar
    output.SetStatus("Object Detection | Network {:.0f} FPS".format(net.GetNetworkFPS()))

    # Exit check
    if not input.IsStreaming() or not output.IsStreaming():
        break
